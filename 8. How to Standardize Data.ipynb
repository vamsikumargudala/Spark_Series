{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac3c3410",
   "metadata": {},
   "source": [
    "### Introduction:\n",
    "\n",
    "**Standardization** means giving labels to pieces of data that might be different but are treated as the same for a specific reason. It's like how we can call a cat by various names like kitty, kitty cat, kitten, or feline. Instead, we can simplify everything by using just \"cat.\" This helps make our data neater and more organized, which is really useful when we're working with data. This process is often used to clean up data and make it easier to work with. Standardization also helps with something called skew, which we'll talk about in a later part of this course called \"Addressing Data Cardinality and Skew.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343c2391",
   "metadata": {},
   "source": [
    "### Two Types of Standardization:\n",
    "\n",
    "There are at least two simple methods to standardize something:\n",
    "\n",
    "+ You can acknowledge when two things are alike but have different names (\"puppy\" and \"dog\") and link them without altering anything.\n",
    "+ You can identify when two things are alike and modify them to match (replace all occurrences of \"puppy\" with \"dog\").\n",
    "\n",
    "To perform these actions using Spark in Python, both methods require creating a custom library of synonyms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2924c2d5",
   "metadata": {},
   "source": [
    "**Standardization through Suggestion**\n",
    "Exercise Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38569d57",
   "metadata": {},
   "source": [
    "Import additional relevant Spark libraries using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c3b8724",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97c8b59a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Spark\\\\sparkhome'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dda9f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7c44ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Vamsi_App_4\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "045900c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "618368d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9e51da",
   "metadata": {},
   "source": [
    "Create a List of Rows, each containing a name and type using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59e41893",
   "metadata": {},
   "outputs": [],
   "source": [
    "pets = [Row(\"annabelle\", \"cat\"),\n",
    "                    Row(\"daisy\", \"kitten\"),\n",
    "                    Row(\"roger\", \"puppy\"),\n",
    "                    Row(\"joe\", \"puppy dog\"),\n",
    "                    Row(\"rosco\", \"dog\"),\n",
    "                    Row(\"julie\", \"feline\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6fafa8",
   "metadata": {},
   "source": [
    "Use the parallelize() function of Spark to turn that List into an RDD as shown in the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ee43d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "petsRDD = spark.sparkContext.parallelize(pets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb9c12b",
   "metadata": {},
   "source": [
    "Create a DataFrame from the RDD and a provided schema using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36a6dcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "petsDF = spark.createDataFrame(petsRDD, ['nickname', 'type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f7a419",
   "metadata": {},
   "source": [
    "#### Filter Dogs:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86006f79",
   "metadata": {},
   "source": [
    "Use the where() function of the DataFrame in combination with the isin() function (of the implicits library) to only keep rows where the name matches a provided list of dog nouns. Print the results to the console as shown in the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5aed520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+\n",
      "|nickname|     type|\n",
      "+--------+---------+\n",
      "|   roger|    puppy|\n",
      "|     joe|puppy dog|\n",
      "|   rosco|      dog|\n",
      "+--------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dogs = petsDF.where(col(\"type\").isin(\"dog\", \"puppy\", \"puppy dog\", \"hound\", \"canine\"))\n",
    "dogs.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b375d3f3",
   "metadata": {},
   "source": [
    "Use the where() function of the DataFrame in combination with the isin() function (of the implicits library) to only keep rows where the name matches a provided list of cat nouns. Print the results to the console as shown in the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f93619a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "| nickname|  type|\n",
      "+---------+------+\n",
      "|annabelle|   cat|\n",
      "|    daisy|kitten|\n",
      "|    julie|feline|\n",
      "+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cats = petsDF.where(col(\"type\").isin([\"cat\", \"kitty\", \"kitten\", \"feline\", \"kitty cat\"]))\n",
    " \n",
    "cats.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136bb2ab",
   "metadata": {},
   "source": [
    "This example also demonstrates that you can pass a list to the isin() function, not just a comma-separated list of strings values as demonstrated in the previous step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d95a4a",
   "metadata": {},
   "source": [
    "### Standardization through Modification\n",
    "\n",
    "\n",
    "In the previous exercise, we would quietly identify animals as a certain type if their type was found in a list of common synonyms for the proper type. In this exercise, we will actually modify our data to be standardized, by replacing the similar type value with its preferred, standard alternative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bbf2ee",
   "metadata": {},
   "source": [
    "Create and utilize a standardize() function to compare the petType to a list of common dog and cat nouns — returning “dog” or “cat”, respectively, if there is a match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea7fbcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(pet):\n",
    "    name = pet[0]\n",
    "    animal_type = pet[1]\n",
    "    \n",
    "    dog_nouns = [\"dog\", \"puppy\", \"puppy dog\", \"hound\", \"canine\"]\n",
    "    cat_nouns = [\"cat\", \"kitty\", \"kitten\", \"feline\", \"kitty cat\"]\n",
    "    \n",
    "    if animal_type in dog_nouns:\n",
    "        return name, \"dog\"\n",
    "    elif animal_type in cat_nouns:\n",
    "        return name, \"cat\"\n",
    "    else:\n",
    "        return pet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0539d3",
   "metadata": {},
   "source": [
    "Then, apply the standardize() function to petsRDD (created in the previous exercise) using the map() function. Hint: You can also use a UDF on the DataFrame instead of this RDD map method, but we’ll cover that in a future exercise!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9fdbc85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+\n",
      "| nickname|type|\n",
      "+---------+----+\n",
      "|annabelle| cat|\n",
      "|    daisy| cat|\n",
      "|    roger| dog|\n",
      "|      joe| dog|\n",
      "|    rosco| dog|\n",
      "|    julie| cat|\n",
      "+---------+----+\n",
      "\n",
      "+---------+---------+\n",
      "| nickname|     type|\n",
      "+---------+---------+\n",
      "|annabelle|      cat|\n",
      "|    daisy|   kitten|\n",
      "|    roger|    puppy|\n",
      "|      joe|puppy dog|\n",
      "|    rosco|      dog|\n",
      "|    julie|   feline|\n",
      "+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "standardizedPets = petsRDD.map(standardize)\n",
    "standardizedPetsDF = spark.createDataFrame(standardizedPets, ['nickname', 'type'])\n",
    " \n",
    "standardizedPetsDF.show()\n",
    "petsDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efbe430",
   "metadata": {},
   "source": [
    "This code defines a function standardize() that compares the type of a pet to lists of common dog and cat nouns. It then applies this function to the pet data, turning the original data into standardized categories of \"dog\" or \"cat\". The output shows how the pets are now consistently labeled as dogs or cats based on the standardized logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a64c6fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParallelCollectionRDD[0] at readRDDFromFile at PythonRDD.scala:287\n"
     ]
    }
   ],
   "source": [
    "print(petsRDD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9c3964",
   "metadata": {},
   "source": [
    "To view the data in RDD's, you need to **collect()** the data to the driver and loop through the result and print the contents of each element of RDD to the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "753011dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annabelle,cat\n",
      "daisy,kitten\n",
      "roger,puppy\n",
      "joe,puppy dog\n",
      "rosco,dog\n",
      "julie,feline\n"
     ]
    }
   ],
   "source": [
    "dataColl=petsRDD.collect()\n",
    "for row in dataColl:\n",
    "    print(row[0] + \",\" +str(row[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b6e79e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
