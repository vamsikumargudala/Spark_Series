{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edc11c6c",
   "metadata": {},
   "source": [
    "Think of filtering data like cleaning out stuff you don't need from a big pile. Just like when you're sorting through your things and keeping only what matters, filtering helps you get rid of irrelevant or messy information in your data.\n",
    "\n",
    "In Spark, doing this is easy and straightforward using a function called **.filter()**. Another option is **.where()**, which does the same thing as .filter(). Just like how you use filters in a coffee machine to get rid of coffee grounds, here you're using filters to get rid of unwanted data. This usually happens when you're preparing data for analysis, and it's a really important step. Just like tidying up your room before a friend visits!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491dbb6d",
   "metadata": {},
   "source": [
    "we will learn how to filter data in a Spark DataFrame step by step (in Python)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc837049",
   "metadata": {},
   "source": [
    "You start by creating a list of animals along with their categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2193a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorized_animals = [(\"dog\", \"pet\"), (\"cat\", \"pet\"), (\"bear\", \"wild\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363d93ac",
   "metadata": {},
   "source": [
    "#### Turning List into RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3ee94a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Spark\\\\sparkhome'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d81936ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1c7aac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Vamsi_App_1\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af589d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "animalDataRDD = spark.sparkContext.parallelize(categorized_animals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a84c3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "animalDFs = spark.createDataFrame(animalDataRDD,['name','category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b08bcb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+\n",
      "|name|category|\n",
      "+----+--------+\n",
      "| dog|     pet|\n",
      "| cat|     pet|\n",
      "|bear|    wild|\n",
      "+----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "animalDFs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f370f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+\n",
      "|name|category|\n",
      "+----+--------+\n",
      "| cat|     pet|\n",
      "+----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nonCats = animalDFs.filter(\"name like 'c%'\")\n",
    "nonCats.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e3db35",
   "metadata": {},
   "source": [
    "In this exercise, you learned how to use Spark's .filter() method to keep or remove specific data from your DataFrame based on conditions. This is like sorting out things you want to keep and things you don't want, just like organizing your belongings for a tidy room."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d82ef6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
