{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdbb4bc9",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "**Ordering** is like putting things in a neat line so they make sense. It's used when you want to show information in a clear way. Think of it as tidying up your data to make it easier to look at. People often use ordering when they're done working with data to show it neatly and organized. This makes the data easier to understand. But remember, ordering is helpful for all sorts of tasks involving data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1f81a8",
   "metadata": {},
   "source": [
    "You can also use **.orderBy()**, which is like a friendlier version of **.sort()**, especially for those who like SQL. Plus, you can also use regular SQL commands on your Spark Dataframes to do sorting, as you'll find out below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd26188",
   "metadata": {},
   "source": [
    "#### Getting Ready for the Exercise\n",
    "\n",
    "In the earlier task labeled \"4.6: How to Aggregate Data,\" we discussed a set of example data and used aggregation (grouping) to answer questions like:\n",
    "\n",
    "+ Which cat is the youngest among our data?\n",
    "+ Which cat is the oldest among our data?\n",
    "\n",
    "Now, we're going to explore another way to answer these same questions using sorting or ordering in Spark. We'll aim to find the youngest and oldest cats in the data again, but this time, we'll take advantage of sorting to achieve our goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48bf81ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Spark\\\\sparkhome'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02635557",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77b154b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Vamsi_App_5\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db91a4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bad9712",
   "metadata": {},
   "source": [
    "Create a List of Rows, each containing a name and type using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30c32f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_previous_pets = [(\"fido\", \"dog\", 4, \"brown\"),\n",
    "                    (\"annabelle\", \"cat\", 15, \"white\"),\n",
    "                    (\"fred\", \"bear\", 29, \"brown\"),\n",
    "                    (\"daisy\", \"cat\", 8, \"black\"),\n",
    "                    (\"jerry\", \"cat\", 1, \"white\"),\n",
    "                    (\"fred\", \"parrot\", 1, \"brown\"),\n",
    "                    (\"gus\", \"fish\", 1, \"gold\"),\n",
    "                    (\"gus\", \"dog\", 11, \"black\"),\n",
    "                    (\"daisy\", \"iguana\", 2, \"green\"),\n",
    "                    (\"rufus\", \"dog\", 10, \"gold\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127e24ad",
   "metadata": {},
   "source": [
    "Use the **parallelize()** function of Spark to turn that List into an RDD as shown in the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2963db15",
   "metadata": {},
   "outputs": [],
   "source": [
    "petsRDD = spark.sparkContext.parallelize(my_previous_pets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec4a843",
   "metadata": {},
   "source": [
    "Create a DataFrame from the RDD and a provided schema using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5217522c",
   "metadata": {},
   "outputs": [],
   "source": [
    "petsDF = spark.createDataFrame(petsRDD, ['nickname', 'type','age','color'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f3a771",
   "metadata": {},
   "source": [
    "First, let's set up the data for analysis. We'll create a temporary table view named 'pets' using the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3985270c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Spark\\sparkhome\\python\\pyspark\\sql\\dataframe.py:330: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "petsDF.registerTempTable('pets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "359d7643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- nickname: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      " |-- color: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "petsDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d156e0a7",
   "metadata": {},
   "source": [
    "Two Approaches to Achieve the Goal:\n",
    "\n",
    "You have two ways to achieve your goal:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbbe3d9",
   "metadata": {},
   "source": [
    "### SQL Approach\n",
    "\n",
    "In this approach, you'll write SQL queries to find the youngest and oldest cats and then display the results using the provided code. Here's the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3a6acc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---+\n",
      "|youngest_cat|age|\n",
      "+------------+---+\n",
      "|       jerry|  1|\n",
      "+------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT nickname AS youngest_cat, \"\n",
    "          \"MIN(age) AS age \"\n",
    "          \"FROM pets \"\n",
    "          \"WHERE type = 'cat' \"\n",
    "          \"GROUP BY nickname \"\n",
    "          \"ORDER BY age ASC \"\n",
    "          \"LIMIT 1\")\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63118ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+\n",
      "|oldest_cat|age|\n",
      "+----------+---+\n",
      "| annabelle| 15|\n",
      "+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT nickname AS oldest_cat, \"\n",
    "          \"MAX(age) AS age \"\n",
    "          \"FROM pets \"\n",
    "          \"WHERE type = 'cat' \"\n",
    "          \"GROUP BY nickname \"\n",
    "          \"ORDER BY age DESC \"\n",
    "          \"LIMIT 1\")\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d438aff4",
   "metadata": {},
   "source": [
    "Leverage the function-chaining alternative to accomplish the same thing. Print the results to the console using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d5b2c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+---+-----+\n",
      "|nickname|type|age|color|\n",
      "+--------+----+---+-----+\n",
      "|   jerry| cat|  1|white|\n",
      "+--------+----+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "petsDF.where(\"type = 'cat'\").sort(\"age\").limit(1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54253ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+---+-----+\n",
      "| nickname|type|age|color|\n",
      "+---------+----+---+-----+\n",
      "|annabelle| cat| 15|white|\n",
      "+---------+----+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "petsDF.where(\"type = 'cat'\").sort(col(\"age\").desc()).limit(1).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9c8cc3",
   "metadata": {},
   "source": [
    "The previous results show that the youngest cat is named Jerry, aged 1 year, and is white in color. On the other hand, the oldest cat, Annabelle, is 15 years old and also white in color.\n",
    "\n",
    "In this exercise, we've grasped the concept of arranging our final data output to present information in a meaningful order that helps us understand it better.\n",
    "\n",
    "In the upcoming section, we'll delve into the concept of Ranking. A hint for you: it involves utilizing sorting and ordering techniques!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748429ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
